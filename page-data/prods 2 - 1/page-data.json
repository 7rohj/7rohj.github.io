{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/prods 2 - 1/",
    "result": {"data":{"cur":{"id":"0c6c31cb-7da4-5200-ac63-3a80673f9346","html":"<p>선형회귀분석의 기본적인 가정이 있다.\r\n선형회귀분석을 하기 전에 검토해봐야할 몇 가지 가정.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"left\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">선형성</td>\n<td align=\"left\">독립변수와 종속변수가 선형적이어야 한다.</td>\n</tr>\n<tr>\n<td align=\"center\">잔차 정규성</td>\n<td align=\"left\">잔차의 기댓값은 0이며 정규분포를 이루어야 한다.</td>\n</tr>\n<tr>\n<td align=\"center\">잔차 독립성</td>\n<td align=\"left\">잔차들은 서로 독립적이어야 한다</td>\n</tr>\n<tr>\n<td align=\"center\">잔차 등분산성</td>\n<td align=\"left\">잔차들의 분산이 일정해야 한다.</td>\n</tr>\n<tr>\n<td align=\"center\">다중 공산성(VIF)</td>\n<td align=\"left\">다중 회귀분석을 수행할 경우 3개 이상의 독립변수 간에 상관관계로 인한 문제가 없어야 한다.</td>\n</tr>\n</tbody>\n</table>\n<p><strong>[아래는 파이썬을 통해 다중공산성 확인 및 변수 제거 실습한 이미지 이다]</strong><br/>\r\n데이터는 <code class=\"language-text\">보스턴 주택 데이터</code></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">import</span> pandas as pd \r\n<span class=\"token function\">import</span> numpy as np\r\n<span class=\"token function\">import</span> statsmodels.api as sm\r\n\r\n<span class=\"token comment\"># 데이터 불러오기</span>\r\nboston <span class=\"token operator\">=</span> pd.read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"./Boston_house.csv\"</span><span class=\"token punctuation\">)</span>\r\nboston_data <span class=\"token operator\">=</span> boston.drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Target'</span><span class=\"token punctuation\">]</span>, <span class=\"token assign-left variable\">axis</span><span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># crim, rm, lstat을 통한 다중 선형회귀분석</span>\r\nx_data <span class=\"token operator\">=</span> boston<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"CRIM\"</span>,<span class=\"token string\">\"RM\"</span>,<span class=\"token string\">\"LSTAT\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token comment\">#변수 여러개</span>\r\ntarget <span class=\"token operator\">=</span> boston<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"Target\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n\r\n<span class=\"token comment\"># for b0, 상수항 추가</span>\r\nx_data1 <span class=\"token operator\">=</span> sm.add_constant<span class=\"token punctuation\">(</span>x_data, has_constant <span class=\"token operator\">=</span> <span class=\"token string\">\"add\"</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># OLS 검정</span>\r\nmulti_model <span class=\"token operator\">=</span> sm.OLS<span class=\"token punctuation\">(</span>target, x_data1<span class=\"token punctuation\">)</span>\r\nfitted_multi_model <span class=\"token operator\">=</span> multi_model.fit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nfitted_multi_model.summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><img src=\"./%5Bols_result.png%5D\" alt=\"사진\"></p>\n<br/>\r\n<br/>\r\n<br/>","excerpt":"선형회귀분석의 기본적인 가정이 있다.\r\n선형회귀분석을 하기 전에 검토해봐야할 몇 가지 가정.   선형성 독립변수와 종속변수가 선형적이어야 한다. 잔차 정규성 잔차의 기댓값은 0이며 정규분포를 이루어야 한다. 잔차 독립성 잔차들은 서로 독립적이어야 한다 잔차 등분산성 잔차들의 분산이 일정해야 한다. 다중 공산성(VIF) 다중 회귀분석을 수행할 경우 3개 이상의 독립변수 간에 상관관계로 인한 문제가 없어야 한다. [아래는 파이썬을 통해 다중공산성 확인 및 변수 제거 실습한 이미지 이다]\r\n데이터는  사진","frontmatter":{"date":"April 05, 2022","title":"선형회귀(2)","categories":"빅분기","author":"강화정","emoji":"🚫"},"fields":{"slug":"/prods 2 - 1/"}},"next":{"id":"f071711f-d9ff-53cb-8df3-b48f0b8242d5","html":"<p>단순 선형 회귀는 독립변수도 하나, 종속변수도 하나인 선형 회귀이다.\r\n실제 값과 회귀 모델의 차이에 따른 오류 값을 남은 오류, 즉 잔차라고 부르며\r\n<code class=\"language-text\">최적의 회귀 모델을 만든다는 것</code>은 바로 전체 데이터의 <code class=\"language-text\">잔차 합이 최소가 되는 모델을 만든다는 의미</code>이다.\r\n동시에 오류 값 합이 최소가 될 수 있는 최적의 회귀 계수를 찾는다는 의미도 된다.</p>\n<p>보통 오류 합을 계산할 때는 <code class=\"language-text\">절댓값을 취해서 더하거나</code>, <code class=\"language-text\">오류 값의 제곱을 구해서 더하는 방식</code>을 취한다.\r\n앞 Meaen Absolute Error, 뒤 Residual Sum of Square</p>\n<p>즉, Error^2 = RSS 이다.</p>\n<p>RSS는 w0 그리고 w1인 식으로 표현할 수 있으며 이 RSS를 최소로 하는 w0,w1, 즉 회귀 계수를 학습을 통해서\r\n찾는 것이 머신러닝 기반 회귀의 핵심 사항이다.</p>\n<p>RSS는 회귀식의 독립변수, 종속변수가 중심 변수가 아니라 회귀 계수인 w 변수가 중심 변수임을 인지하는 것이 매우 중요하다.\r\n학습 데이터로 입력되는 독립변수와 종속변수는 RSS에서는 모두 상수로 간주한다.</p>\n<p>회귀에서 이 <code class=\"language-text\">RSS</code>는 <code class=\"language-text\">비용(Cost)</code>이며 w변수로 구성되는 RSS를 비용 함수라고 한다.\r\n머신러닝 회귀 알고리즘은 데이터를 계속 학습하면서 이 비용 함수가 반환하는 값을 지속해서 감소시키고 최종적으로는\r\n<code class=\"language-text\">더 이상 감소하지 않는 최소의 오류 값을 구하는 것</code>이다. 비용함수를 손실함수(loss function)라고도 한다.</p>\n<h3 id=\"-비용-최소화하기---경사-하강법-gradient-descent-\" style=\"position:relative;\"><a href=\"#-%EB%B9%84%EC%9A%A9-%EC%B5%9C%EC%86%8C%ED%99%94%ED%95%98%EA%B8%B0---%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95-gradient-descent-\" aria-label=\" 비용 최소화하기   경사 하강법 gradient descent  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>※ 비용 최소화하기 - 경사 하강법 (Gradient Descent) ※</h3>\n<p>경사 하강법은 반복적으로 비용 함수의 반환 값 즉 예측값과 실제 값의 차이가 작아지는 방향성을 가지고 W 파라미터를 지속해서 보정해 나간다.\r\n최초 오류 값이 100이었다면 두 번째 오류 값은 100보다 작은 90, 세 번째는 80과 같은 방식으로 지속해서 오류를 감소시키는 방향으로 W 값을 계속 업데이트해 나간다.\r\n그리고 오류 값이 더 이상 작아지지 않으면 그 오류 값을 최소 비용으로 판단하고 그 때의 W 값을 최적 파라미터로 반환한다.</p>\n<p><code class=\"language-text\">경사하강법은 수행 시간이 매우 오래 걸린다</code>는 단점이 있기 때문에 실전에서는 대부분 확률적 경사 하강법을 이용한다.\r\n확률적 경사 하강법은 전체 입력 데이터로 w가 업데이트되는 값을 계산하는 것이 아니라 <strong>일부 데이터만 이용해</strong> w가 업데이트되는 값을 계산하므로\r\n경사 하강법에 비해서 빠른 속도를 보장한다. 따라서 대용량의 데이터의 경우 대부분 <code class=\"language-text\">확률적 경사 하강법</code>이나 <code class=\"language-text\">미니 배치 확률적 경사 하강법</code>을 이용해 최적 비용함수를 도출한다.</p>\n<br/>\r\n<br/>\r\n<br/>","frontmatter":{"date":"April 05, 2022","title":"선형회귀","categories":"빅분기","author":"강화정","emoji":"🚫"},"fields":{"slug":"/prods 2/"}},"prev":{"id":"88bf167d-93c4-5da3-813d-6a5d3bc3e783","html":"<p>세상의 모든 관계를 직선으로만 표현할 수 없다. 회귀가 독립변수의 단항식이 아닌 2차, 3차 방정식과 같은 다항식으로 표현되는 것을 다항 회귀라고 한다.</p>\n<p>한가지 주의할 것은 다항 회귀를 비선형 회귀로 혼동하기 쉽지만, <code class=\"language-text\">다항 회귀는 선형 회귀라는 점</code>이다.\r\n데이터 세트에 따라 피처 X에 대해 Target Y 값의 관계를 단순 선형 회귀 직선형으로 표현한 것보다 다항 회귀 곡선형으로 표현한 것이 더 예측 성능이 높은 경우가 있다.</p>\n<h3 id=\"다항-회귀를-이용한-과소적합-및-과적합-이해\" style=\"position:relative;\"><a href=\"#%EB%8B%A4%ED%95%AD-%ED%9A%8C%EA%B7%80%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-%EB%B0%8F-%EA%B3%BC%EC%A0%81%ED%95%A9-%EC%9D%B4%ED%95%B4\" aria-label=\"다항 회귀를 이용한 과소적합 및 과적합 이해 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>다항 회귀를 이용한 과소적합 및 과적합 이해</h3>\n<p>다항 회귀는 피처의 직선적 관계가 아닌 복잡한 다항 관계를 모델링할 수 있다. 다항식의 차수가 높아질 수록 매우 복잡한 피처 간의 관계까지 모델링이 가능하다.\r\n하지만 다항 회귀의 차수를 높일 수록 <code class=\"language-text\">학습 데이터에만</code> 너무 맞춘 학습이 이뤄져서 정작 테스트 데이터 환경에서는 오히려 예측 정확도가 떨어진다.\r\n<code class=\"language-text\">즉, 차수가 높아질수록 과적합의 문제가 크게 발생</code>한다.</p>\n<h3 id=\"편향ㅡ분산-트레이드오프bias-variance-trade-off\" style=\"position:relative;\"><a href=\"#%ED%8E%B8%ED%96%A5%E3%85%A1%EB%B6%84%EC%82%B0-%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%93%9C%EC%98%A4%ED%94%84bias-variance-trade-off\" aria-label=\"편향ㅡ분산 트레이드오프bias variance trade off permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>편향ㅡ분산 트레이드오프(Bias-Variance Trade off)</h3>\n<p>편향ㅡ분산 트레이드오프는 머신러닝이 극복해야 할 가장 중요한 이슈 중 하나다. Degree 1과 같은 모델은 매우 단순화된 모델로서 지나치게 한 방향성으로 치우친 경향이 있다.\r\n이런 모델을 <code class=\"language-text\">고편향성(High Bias)</code>을 가졌다고 표현한다. 반대로 Degree 15와 같은 모델은 학습 데이터 하나 하나으이 특성을 반영하면서 매우 복잡한 모델이 되었고\r\n지나치게 높은 변동성을 가지게 된다. 이런 모델을 <code class=\"language-text\">고분산성(High Variance)</code>을 가졌다고 표현한다.</p>\n<ul>\n<li>저편향/저분산은 예측 결과가 실제 결과에 매우 잘 근접하면서도 예측 변동이 크지 않고 특정 부분에 집중돼 있는 아주 뛰어난 성능을 보인다. (아주 드물게 좋은 경우)</li>\n<li>저편향/고분산은 쳬측 결과가 실제 결과에 비교적 근접하지만, 예측 결과가 실제 결과를 중심으로 꽤 넓은 부분에 분포돼 있다.</li>\n<li>고편향/저분산은 정확한 결과에서 벗어나면서도 예측이 특정 부분에 집중돼 있다.</li>\n<li>고편향/고분산은 정확한 예측 결과를 벗어나면서도 넓은 부분에 분포돼 있다.</li>\n</ul>\n<p><code class=\"language-text\">일반적으로 편향과 분산은 한 쪽이 높으면 한 쪽이 낮아지는 경향</code>이 있다.</p>\n<h4 id=\"즉-편향이-높으면-분산은-낮아지고--과소적합-반대로-분산이-높으면-편향이-낮아진다--과적합\" style=\"position:relative;\"><a href=\"#%EC%A6%89-%ED%8E%B8%ED%96%A5%EC%9D%B4-%EB%86%92%EC%9C%BC%EB%A9%B4-%EB%B6%84%EC%82%B0%EC%9D%80-%EB%82%AE%EC%95%84%EC%A7%80%EA%B3%A0--%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-%EB%B0%98%EB%8C%80%EB%A1%9C-%EB%B6%84%EC%82%B0%EC%9D%B4-%EB%86%92%EC%9C%BC%EB%A9%B4-%ED%8E%B8%ED%96%A5%EC%9D%B4-%EB%82%AE%EC%95%84%EC%A7%84%EB%8B%A4--%EA%B3%BC%EC%A0%81%ED%95%A9\" aria-label=\"즉 편향이 높으면 분산은 낮아지고  과소적합 반대로 분산이 높으면 편향이 낮아진다  과적합 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>즉, 편향이 높으면 분산은 낮아지고 => 과소적합, 반대로 분산이 높으면 편향이 낮아진다 => 과적합</h4>\n<h3 id=\"덧붙여서\" style=\"position:relative;\"><a href=\"#%EB%8D%A7%EB%B6%99%EC%97%AC%EC%84%9C\" aria-label=\"덧붙여서 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(덧붙여서)</h3>\n<p>저편향/저분산은 이상에 가깝다. 결국 데이터 분석의 목적이 무엇인지에 따라 적절한 선택을 해야 한다.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">^.^</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">결국 데이터 분석가는 <code class=\"language-text\">고편향/저분산</code> 과 <code class=\"language-text\">저편향/고분산</code> 중에서 하나를 골라야만 하며 훌륭한 데이터 분석가라면 추론할 때는 <code class=\"language-text\">고편향/저분산</code>을 고를 것이다. 어차피 데이터 분석가는 비즈니스 현장에서 상사나 이해관계자가 실제로 사용할 수 있고, 설명할 수 있는 모형을 만들어야 하니까. 아무도 이해 못하고 해석도 못해서 사용할 수 없는 모형을 만들면 안된다. 반면에 데이터 분석의 목적이 예측이라면 데이터 분석가는 <code class=\"language-text\">저편향/고분산</code>을 고를 거다. 모형이 복잡하더라도 정답에 가까운 결과물을 도출해야 하기 때문이다.</td>\n</tr>\n</tbody>\n</table>\n<p>⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀<span style=\"font-size:75%\">출처 : 감으로만 일하던 김팀장은 어떻게 데이터 좀 아는 팀장이 되었나</span></p>\n<br/>\r\n<br/>\r\n<br/>","frontmatter":{"date":"April 07, 2022","title":"다항회귀","categories":"빅분기","author":"강화정","emoji":"⁉"},"fields":{"slug":"/prods 3/"}},"site":{"siteMetadata":{"siteUrl":"https://7rohj.github.io","comments":{"utterances":{"repo":"https://7rohj.github.io"}}}}},"pageContext":{"slug":"/prods 2 - 1/","nextSlug":"/prods 2/","prevSlug":"/prods 3/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}