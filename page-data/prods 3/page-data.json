{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/prods 3/",
    "result": {"data":{"cur":{"id":"88bf167d-93c4-5da3-813d-6a5d3bc3e783","html":"<p>세상의 모든 관계를 직선으로만 표현할 수 없다. 회귀가 독립변수의 단항식이 아닌 2차, 3차 방정식과 같은 다항식으로 표현되는 것을 다항 회귀라고 한다.</p>\n<p>한가지 주의할 것은 다항 회귀를 비선형 회귀로 혼동하기 쉽지만, <code class=\"language-text\">다항 회귀는 선형 회귀라는 점</code>이다.\r\n데이터 세트에 따라 피처 X에 대해 Target Y 값의 관계를 단순 선형 회귀 직선형으로 표현한 것보다 다항 회귀 곡선형으로 표현한 것이 더 예측 성능이 높은 경우가 있다.</p>\n<h3 id=\"다항-회귀를-이용한-과소적합-및-과적합-이해\" style=\"position:relative;\"><a href=\"#%EB%8B%A4%ED%95%AD-%ED%9A%8C%EA%B7%80%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-%EB%B0%8F-%EA%B3%BC%EC%A0%81%ED%95%A9-%EC%9D%B4%ED%95%B4\" aria-label=\"다항 회귀를 이용한 과소적합 및 과적합 이해 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>다항 회귀를 이용한 과소적합 및 과적합 이해</h3>\n<p>다항 회귀는 피처의 직선적 관계가 아닌 복잡한 다항 관계를 모델링할 수 있다. 다항식의 차수가 높아질 수록 매우 복잡한 피처 간의 관계까지 모델링이 가능하다.\r\n하지만 다항 회귀의 차수를 높일 수록 <code class=\"language-text\">학습 데이터에만</code> 너무 맞춘 학습이 이뤄져서 정작 테스트 데이터 환경에서는 오히려 예측 정확도가 떨어진다.\r\n<code class=\"language-text\">즉, 차수가 높아질수록 과적합의 문제가 크게 발생</code>한다.</p>\n<h3 id=\"편향ㅡ분산-트레이드오프bias-variance-trade-off\" style=\"position:relative;\"><a href=\"#%ED%8E%B8%ED%96%A5%E3%85%A1%EB%B6%84%EC%82%B0-%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%93%9C%EC%98%A4%ED%94%84bias-variance-trade-off\" aria-label=\"편향ㅡ분산 트레이드오프bias variance trade off permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>편향ㅡ분산 트레이드오프(Bias-Variance Trade off)</h3>\n<p>편향ㅡ분산 트레이드오프는 머신러닝이 극복해야 할 가장 중요한 이슈 중 하나다. Degree 1과 같은 모델은 매우 단순화된 모델로서 지나치게 한 방향성으로 치우친 경향이 있다.\r\n이런 모델을 <code class=\"language-text\">고편향성(High Bias)</code>을 가졌다고 표현한다. 반대로 Degree 15와 같은 모델은 학습 데이터 하나 하나으이 특성을 반영하면서 매우 복잡한 모델이 되었고\r\n지나치게 높은 변동성을 가지게 된다. 이런 모델을 <code class=\"language-text\">고분산성(High Variance)</code>을 가졌다고 표현한다.</p>\n<ul>\n<li>저편향/저분산은 예측 결과가 실제 결과에 매우 잘 근접하면서도 예측 변동이 크지 않고 특정 부분에 집중돼 있는 아주 뛰어난 성능을 보인다. (아주 드물게 좋은 경우)</li>\n<li>저편향/고분산은 쳬측 결과가 실제 결과에 비교적 근접하지만, 예측 결과가 실제 결과를 중심으로 꽤 넓은 부분에 분포돼 있다.</li>\n<li>고편향/저분산은 정확한 결과에서 벗어나면서도 예측이 특정 부분에 집중돼 있다.</li>\n<li>고편향/고분산은 정확한 예측 결과를 벗어나면서도 넓은 부분에 분포돼 있다.</li>\n</ul>\n<p><code class=\"language-text\">일반적으로 편향과 분산은 한 쪽이 높으면 한 쪽이 낮아지는 경향</code>이 있다.</p>\n<h4 id=\"즉-편향이-높으면-분산은-낮아지고--과소적합-반대로-분산이-높으면-편향이-낮아진다--과적합\" style=\"position:relative;\"><a href=\"#%EC%A6%89-%ED%8E%B8%ED%96%A5%EC%9D%B4-%EB%86%92%EC%9C%BC%EB%A9%B4-%EB%B6%84%EC%82%B0%EC%9D%80-%EB%82%AE%EC%95%84%EC%A7%80%EA%B3%A0--%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-%EB%B0%98%EB%8C%80%EB%A1%9C-%EB%B6%84%EC%82%B0%EC%9D%B4-%EB%86%92%EC%9C%BC%EB%A9%B4-%ED%8E%B8%ED%96%A5%EC%9D%B4-%EB%82%AE%EC%95%84%EC%A7%84%EB%8B%A4--%EA%B3%BC%EC%A0%81%ED%95%A9\" aria-label=\"즉 편향이 높으면 분산은 낮아지고  과소적합 반대로 분산이 높으면 편향이 낮아진다  과적합 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>즉, 편향이 높으면 분산은 낮아지고 => 과소적합, 반대로 분산이 높으면 편향이 낮아진다 => 과적합</h4>\n<h3 id=\"덧붙여서\" style=\"position:relative;\"><a href=\"#%EB%8D%A7%EB%B6%99%EC%97%AC%EC%84%9C\" aria-label=\"덧붙여서 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(덧붙여서)</h3>\n<p>저편향/저분산은 이상에 가깝다. 결국 데이터 분석의 목적이 무엇인지에 따라 적절한 선택을 해야 한다.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">^.^</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">결국 데이터 분석가는 <code class=\"language-text\">고편향/저분산</code> 과 <code class=\"language-text\">저편향/고분산</code> 중에서 하나를 골라야만 하며 훌륭한 데이터 분석가라면 추론할 때는 <code class=\"language-text\">고편향/저분산</code>을 고를 것이다. 어차피 데이터 분석가는 비즈니스 현장에서 상사나 이해관계자가 실제로 사용할 수 있고, 설명할 수 있는 모형을 만들어야 하니까. 아무도 이해 못하고 해석도 못해서 사용할 수 없는 모형을 만들면 안된다. 반면에 데이터 분석의 목적이 예측이라면 데이터 분석가는 <code class=\"language-text\">저편향/고분산</code>을 고를 거다. 모형이 복잡하더라도 정답에 가까운 결과물을 도출해야 하기 때문이다.</td>\n</tr>\n</tbody>\n</table>\n<p>⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀<span style=\"font-size:75%\">출처 : 감으로만 일하던 김팀장은 어떻게 데이터 좀 아는 팀장이 되었나</span></p>\n<br/>\r\n<br/>\r\n<br/>","excerpt":"세상의 모든 관계를 직선으로만 표현할 수 없다. 회귀가 독립변수의 단항식이 아닌 2차, 3차 방정식과 같은 다항식으로 표현되는 것을 다항 회귀라고 한다. 한가지 주의할 것은 다항 회귀를 비선형 회귀로 혼동하기 쉽지만, 이다.\r\n데이터 세트에 따라 피처 X에 대해 Target Y 값의 관계를 단순 선형 회귀 직선형으로 표현한 것보다 다항 회귀 곡선형으로 표현한 것이 더 예측 성능이 높은 경우가 있다. 다항 회귀를 이용한 과소적합 및 과적합 이해 다항 회귀는 피처의 직선적 관계가 아닌 복잡한 다항 관계를 모델링할 수 있다. 다항식의 차수가 높아질 수록 매우 복잡한 피처 간의 관계까지 모델링이 가능하다.\r\n하지만 다항 회귀의 차수를 높일 수록  너무 맞춘 학습이 이뤄져서 정작 테스트 데이터 환경에서는 오히려 예측 정확도가 떨어진다.\r\n한다. 편향ㅡ분산 트레이드오프(Bias-Variance Trade off) 편향ㅡ분산 트레이드오프는 머신러닝이 극복해야 할 가장 중요한 이슈 중 하나다. …","frontmatter":{"date":"April 07, 2022","title":"다항회귀","categories":"빅분기","author":"강화정","emoji":"⁉"},"fields":{"slug":"/prods 3/"}},"next":{"id":"0c6c31cb-7da4-5200-ac63-3a80673f9346","html":"<p>선형회귀분석의 기본적인 가정이 있다.\r\n<code class=\"language-text\">선형회귀분석을 하기 전에 검토해봐야할 몇 가지 가정.</code></p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"left\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">선형성</td>\n<td align=\"left\">독립변수와 종속변수가 선형적이어야 한다.</td>\n</tr>\n<tr>\n<td align=\"center\">잔차 정규성</td>\n<td align=\"left\">잔차의 기댓값은 0이며 정규분포를 이루어야 한다.</td>\n</tr>\n<tr>\n<td align=\"center\">잔차 독립성</td>\n<td align=\"left\">잔차들은 서로 독립적이어야 한다</td>\n</tr>\n<tr>\n<td align=\"center\">잔차 등분산성</td>\n<td align=\"left\">잔차들의 분산이 일정해야 한다.</td>\n</tr>\n<tr>\n<td align=\"center\">다중 공선성(VIF)</td>\n<td align=\"left\">다중 회귀분석을 수행할 경우 3개 이상의 독립변수 간에 상관관계로 인한 문제가 없어야 한다.</td>\n</tr>\n</tbody>\n</table>\n<br/>\r\n<br/>\r\n<br/>\n<p><strong>[아래는 파이썬을 통해 다중공산성 확인 및 변수 제거 실습한 이미지 이다]</strong><br/>\r\n데이터는 <code class=\"language-text\">보스턴 주택 데이터</code><br/></p>\n<h2 id=\"-1-\" style=\"position:relative;\"><a href=\"#-1-\" aria-label=\" 1  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>〰 1 〰</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">import</span> pandas as pd \r\n<span class=\"token function\">import</span> numpy as np\r\n<span class=\"token function\">import</span> statsmodels.api as sm\r\n\r\n<span class=\"token comment\"># 데이터 불러오기</span>\r\nboston <span class=\"token operator\">=</span> pd.read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">\"./Boston_house.csv\"</span><span class=\"token punctuation\">)</span>\r\nboston_data <span class=\"token operator\">=</span> boston.drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Target'</span><span class=\"token punctuation\">]</span>, <span class=\"token assign-left variable\">axis</span><span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># crim, rm, lstat을 통한 다중 선형회귀분석</span>\r\nx_data <span class=\"token operator\">=</span> boston<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"CRIM\"</span>,<span class=\"token string\">\"RM\"</span>,<span class=\"token string\">\"LSTAT\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token comment\">#변수 여러개</span>\r\ntarget <span class=\"token operator\">=</span> boston<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"Target\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\n\r\n<span class=\"token comment\"># for b0, 상수항 추가</span>\r\nx_data1 <span class=\"token operator\">=</span> sm.add_constant<span class=\"token punctuation\">(</span>x_data, has_constant <span class=\"token operator\">=</span> <span class=\"token string\">\"add\"</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># OLS 검정</span>\r\nmulti_model <span class=\"token operator\">=</span> sm.OLS<span class=\"token punctuation\">(</span>target, x_data1<span class=\"token punctuation\">)</span>\r\nfitted_multi_model <span class=\"token operator\">=</span> multi_model.fit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nfitted_multi_model.summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"code-classlanguage-textcrimrmlstatcode-ols-결과\" style=\"position:relative;\"><a href=\"#code-classlanguage-textcrimrmlstatcode-ols-%EA%B2%B0%EA%B3%BC\" aria-label=\"code classlanguage textcrimrmlstatcode ols 결과 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">\"CRIM\",\"RM\",\"LSTAT\"</code> OLS 결과</h3>\n<p><img src=\"https://github.com/7rohj/7rohj.github.io/blob/4b2a9b2c79038944080b02ea7a44705979f6f415/content/prods%202%20-%201/olsresult.png?raw=true\" alt=\"picture\"></p>\n<br/>\r\n<br/>\r\n<br/>\n<h2 id=\"-2-\" style=\"position:relative;\"><a href=\"#-2-\" aria-label=\" 2  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>〰 2 〰</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\">## boston data에서 원하는 변수만 뽑아오기</span>\r\nx_data2 <span class=\"token operator\">=</span> boston<span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'CRIM'</span>,<span class=\"token string\">'RM'</span>, <span class=\"token string\">'LSTAT'</span>, <span class=\"token string\">'B'</span>, <span class=\"token string\">'TAX'</span>, <span class=\"token string\">'AGE'</span>, <span class=\"token string\">'ZN'</span>, <span class=\"token string\">'NOX'</span>, <span class=\"token string\">'INDUS'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\r\nx_data2.head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># 상수항 추가</span>\r\nx_data2_ <span class=\"token operator\">=</span> sm.add_constant<span class=\"token punctuation\">(</span>x_data2, has_constant <span class=\"token operator\">=</span> <span class=\"token string\">\"add\"</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># 회귀모델 적합</span>\r\nmulti_model2 <span class=\"token operator\">=</span> sm.OLS<span class=\"token punctuation\">(</span>target, x_data2_<span class=\"token punctuation\">)</span>\r\nfitted_multi_model2 <span class=\"token operator\">=</span> multi_model2.fit<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\n\r\n<span class=\"token comment\"># 결과 출력</span>\r\nfitted_multi_model2.summary<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"code-classlanguage-textfull-featurescode-ols-결과\" style=\"position:relative;\"><a href=\"#code-classlanguage-textfull-featurescode-ols-%EA%B2%B0%EA%B3%BC\" aria-label=\"code classlanguage textfull featurescode ols 결과 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">FULL FEATURES</code> OLS 결과</h3>\n<p><img src=\"https://github.com/7rohj/7rohj.github.io/blob/7f3956c123d04a5f9b1539c99feefc038c66455e/content/prods%202%20-%201/olsresult2.png?raw=true\" alt=\"picture\"></p>\n<p>*Warnings 에서의 2번 항목이 생겼다. 다중공산성 주의!</p>\n<blockquote>\n<p>강한 다중공선성 또는 다른 numerical 문제가 발생했다고 암시.</p>\n</blockquote>\n<br/>\r\n<br/>\r\n<br/>\n<h2 id=\"-3-\" style=\"position:relative;\"><a href=\"#-3-\" aria-label=\" 3  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>〰 3 〰</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># 변수끼리 산점도를 시각화</span>\r\nsns.pairplot<span class=\"token punctuation\">(</span>x_data2<span class=\"token punctuation\">)</span>\r\nplt.show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"code-classlanguage-textsnspairplotcode-결과\" style=\"position:relative;\"><a href=\"#code-classlanguage-textsnspairplotcode-%EA%B2%B0%EA%B3%BC\" aria-label=\"code classlanguage textsnspairplotcode 결과 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">sns.pairplot</code> 결과</h3>\n<p><img src=\"https://github.com/7rohj/7rohj.github.io/blob/7f3956c123d04a5f9b1539c99feefc038c66455e/content/prods%202%20-%201/pairplot.png?raw=true\" alt=\"picture\"></p>\n<p>그림에는 없지만 heatmap을 이용해 상관 matrix를 확인했을때 <code class=\"language-text\">0.5가 넘어가는 변수들간의 상관관계</code>가 빈출되는 것은\r\n충분히 <code class=\"language-text\">다중공선성 발생</code>을 의심할 수 있다. 즉, 그 변수들은 제거해 주는게 이롭다고 판단할 수 있는 것이다.\r\n위 그림에서 보이듯 음 또는 양의 상관관계를 나타내는 그래프들의 변수들 또한 그렇다고 얘기할 수 있다.</p>\n<br/>\r\n<br/>\r\n<br/>\n<h2 id=\"-4-\" style=\"position:relative;\"><a href=\"#-4-\" aria-label=\" 4  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>〰 4 〰</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">from statsmodels.stats.ouliers_influence <span class=\"token function\">import</span> variance_inflation_factor \r\n\r\n<span class=\"token comment\"># VIF사용을 위한 라이브러리, statsmodels안에 존재한다.</span>\r\n<span class=\"token comment\"># 사실 모든 통계기법이 statsmodels 모듈에 존재하여 </span>\r\n<span class=\"token comment\"># 이 중에 필요한 통계기법을 찾아 import를 진행하면 된다.</span>\r\n\r\nvif <span class=\"token operator\">=</span> pd.DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nvif<span class=\"token punctuation\">[</span><span class=\"token string\">\"VIF Factor\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>varinace_inflation_factor<span class=\"token punctuation\">(</span>x_data2.values, i<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> <span class=\"token for-or-select variable\">i</span> <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>x_data2.shape<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\r\nvif<span class=\"token punctuation\">[</span><span class=\"token string\">\"features\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> x_data4.columns\r\nvif</code></pre></div>","frontmatter":{"date":"April 05, 2022","title":"선형회귀(2)","categories":"빅분기","author":"강화정","emoji":"🚫"},"fields":{"slug":"/prods 2 - 1/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://7rohj.github.io","comments":{"utterances":{"repo":"https://7rohj.github.io"}}}}},"pageContext":{"slug":"/prods 3/","nextSlug":"/prods 2 - 1/","prevSlug":""}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}