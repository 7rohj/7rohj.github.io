{
    "componentChunkName": "component---src-templates-blog-template-js",
    "path": "/prods 4/",
    "result": {"data":{"cur":{"id":"f1b7929b-2c8d-5222-8444-e11046ccb065","html":"<p>일단 null 값이 있는 row는 drop 해주고,\r\n회귀 모델을 적용하기 전에 타깃 값의 분포도가 정규 분포인지 확인한다. (drop 말고도 다양한 방법이 있음. 다음에 다뤄보도록 해보자)</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">import</span> warnings\r\nwarnings.filterwarnings<span class=\"token punctuation\">(</span><span class=\"token string\">'ignore'</span><span class=\"token punctuation\">)</span>\r\n<span class=\"token function\">import</span> pandas as pd\r\n<span class=\"token function\">import</span> numpy as np\r\n<span class=\"token function\">import</span> seaborn as sns\r\n<span class=\"token function\">import</span> matplotlib.pyplot as plt\r\n%matplotlib inline\r\n\r\nhouse_df_org <span class=\"token operator\">=</span> pd.read_csv<span class=\"token punctuation\">(</span><span class=\"token string\">'house_price.csv'</span><span class=\"token punctuation\">)</span>\r\nhouse_df <span class=\"token operator\">=</span> house_df_org.copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 같은 데이터 프레임 복사.</span>\r\nhouse_df.head<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">print<span class=\"token punctuation\">(</span><span class=\"token string\">'데이터 세트의 Shape:'</span>, house_df.shape<span class=\"token punctuation\">)</span>\r\nprint<span class=\"token punctuation\">(</span><span class=\"token string\">'\\n전체 피처의 type \\n'</span>, house_df.dtypes.value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">))</span>\r\n<span class=\"token assign-left variable\">isnull_series</span><span class=\"token operator\">=</span>house_df.isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>.sum<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\r\nprint<span class=\"token punctuation\">(</span><span class=\"token string\">'\\nNull 칼럼과 그 건수:\\n'</span>, isnull_series<span class=\"token punctuation\">[</span>isnull_series<span class=\"token operator\">></span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>.sort_values<span class=\"token punctuation\">(</span>ascending<span class=\"token operator\">=</span>False<span class=\"token punctuation\">))</span></code></pre></div>\n<p>결과는 생략 <code class=\"language-text\">o.~</code></p>\n<br/>\r\n<br/>\n<p>회귀 모델을 적용하기 잔에 타깃 값의 분포도가 정규 분포인지 확인해야 한다.\r\n위 데이터는 데이터 값의 분포가 중심에서 왼쪽으로 치우친 형태로 정규 분포에서 벗어나 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">plt.title<span class=\"token punctuation\">(</span><span class=\"token string\">'Original Sale Price Histogram'</span><span class=\"token punctuation\">)</span>\r\nsns.distplot<span class=\"token punctuation\">(</span>trainDF<span class=\"token punctuation\">[</span><span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br/>\r\n<br/>\n<h3 id=\"point\" style=\"position:relative;\"><a href=\"#point\" aria-label=\"point permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>POINT</h3>\n<p><code class=\"language-text\">정규 분포가 아닌 결과값</code>을 정규 분포 형태로 변환하기 위해 <code class=\"language-text\">로그 변환(Log Transformation)</code>을 적용한다.\r\n<strong>넘파이의 <code class=\"language-text\">log1p()</code>를 이용해 로그 변환한 결괏값을 기반으로 학습한 뒤, 예측 시에는 다시 결괏값을 <code class=\"language-text\">expm1()</code>으로 추후에 환원</strong>하면 된다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">plt.title<span class=\"token punctuation\">(</span><span class=\"token string\">'Log Transformed Sale Price Histogram'</span><span class=\"token punctuation\">)</span>\r\nlog_SalePrice <span class=\"token operator\">=</span> np.log1p<span class=\"token punctuation\">(</span>house_df<span class=\"token punctuation\">[</span><span class=\"token string\">'salePrice'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\r\nsns.distplot<span class=\"token punctuation\">(</span>log_SalePrice<span class=\"token punctuation\">)</span></code></pre></div>\n<br/>\r\n<br/>\n<p>그리고 문자형 피처는 <code class=\"language-text\">get_dummies()</code>를 이용해준다. 만약 Gender 라는 칼럼이 있으면 Gender_M, Gender_F 하고 해당되는 부분에 1이라는 값이 주어지는 형태의 테이블로 바뀜\r\n<br/>\r\n<br/>\r\n<br/></p>","excerpt":"일단 null 값이 있는 row는 drop 해주고,\r\n회귀 모델을 적용하기 전에 타깃 값의 분포도가 정규 분포인지 확인한다. (drop 말고도 다양한 방법이 있음. 다음에 다뤄보도록 해보자) 결과는 생략  회귀 모델을 적용하기 잔에 타깃 값의 분포도가 정규 분포인지 확인해야 한다.\r\n위 데이터는 데이터 값의 분포가 중심에서 왼쪽으로 치우친 형태로 정규 분포에서 벗어나 있다. POINT 을 정규 분포 형태로 변환하기 위해 을 적용한다.\r\n넘파이의 를 이용해 로그 변환한 결괏값을 기반으로 학습한 뒤, 예측 시에는 다시 결괏값을 으로 추후에 환원하면 된다. 그리고 문자형 피처는 를 이용해준다. 만약 Gender 라는 칼럼이 있으면 Gender_M, Gender_F 하고 해당되는 부분에 1이라는 값이 주어지는 형태의 테이블로 바뀜","frontmatter":{"date":"April 08, 2022","title":"데이터 사전처리(Preprocessing)","categories":"빅분기","author":"강화정","emoji":"🌱"},"fields":{"slug":"/prods 4/"}},"next":{"id":"88bf167d-93c4-5da3-813d-6a5d3bc3e783","html":"<p>세상의 모든 관계를 직선으로만 표현할 수 없다. 회귀가 독립변수의 단항식이 아닌 2차, 3차 방정식과 같은 다항식으로 표현되는 것을 다항 회귀라고 한다.</p>\n<p>한가지 주의할 것은 다항 회귀를 비선형 회귀로 혼동하기 쉽지만, <code class=\"language-text\">다항 회귀는 선형 회귀라는 점</code>이다.\r\n데이터 세트에 따라 피처 X에 대해 Target Y 값의 관계를 단순 선형 회귀 직선형으로 표현한 것보다 다항 회귀 곡선형으로 표현한 것이 더 예측 성능이 높은 경우가 있다.</p>\n<h3 id=\"다항-회귀를-이용한-과소적합-및-과적합-이해\" style=\"position:relative;\"><a href=\"#%EB%8B%A4%ED%95%AD-%ED%9A%8C%EA%B7%80%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-%EB%B0%8F-%EA%B3%BC%EC%A0%81%ED%95%A9-%EC%9D%B4%ED%95%B4\" aria-label=\"다항 회귀를 이용한 과소적합 및 과적합 이해 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>다항 회귀를 이용한 과소적합 및 과적합 이해</h3>\n<p>다항 회귀는 피처의 직선적 관계가 아닌 복잡한 다항 관계를 모델링할 수 있다. 다항식의 차수가 높아질 수록 매우 복잡한 피처 간의 관계까지 모델링이 가능하다.\r\n하지만 다항 회귀의 차수를 높일 수록 <code class=\"language-text\">학습 데이터에만</code> 너무 맞춘 학습이 이뤄져서 정작 테스트 데이터 환경에서는 오히려 예측 정확도가 떨어진다.\r\n<code class=\"language-text\">즉, 차수가 높아질수록 과적합의 문제가 크게 발생</code>한다.</p>\n<h3 id=\"편향ㅡ분산-트레이드오프bias-variance-trade-off\" style=\"position:relative;\"><a href=\"#%ED%8E%B8%ED%96%A5%E3%85%A1%EB%B6%84%EC%82%B0-%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%93%9C%EC%98%A4%ED%94%84bias-variance-trade-off\" aria-label=\"편향ㅡ분산 트레이드오프bias variance trade off permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>편향ㅡ분산 트레이드오프(Bias-Variance Trade off)</h3>\n<p>편향ㅡ분산 트레이드오프는 머신러닝이 극복해야 할 가장 중요한 이슈 중 하나다. Degree 1과 같은 모델은 매우 단순화된 모델로서 지나치게 한 방향성으로 치우친 경향이 있다.\r\n이런 모델을 <code class=\"language-text\">고편향성(High Bias)</code>을 가졌다고 표현한다. 반대로 Degree 15와 같은 모델은 학습 데이터 하나 하나으이 특성을 반영하면서 매우 복잡한 모델이 되었고\r\n지나치게 높은 변동성을 가지게 된다. 이런 모델을 <code class=\"language-text\">고분산성(High Variance)</code>을 가졌다고 표현한다.</p>\n<ul>\n<li>저편향/저분산은 예측 결과가 실제 결과에 매우 잘 근접하면서도 예측 변동이 크지 않고 특정 부분에 집중돼 있는 아주 뛰어난 성능을 보인다. (아주 드물게 좋은 경우)</li>\n<li>저편향/고분산은 쳬측 결과가 실제 결과에 비교적 근접하지만, 예측 결과가 실제 결과를 중심으로 꽤 넓은 부분에 분포돼 있다.</li>\n<li>고편향/저분산은 정확한 결과에서 벗어나면서도 예측이 특정 부분에 집중돼 있다.</li>\n<li>고편향/고분산은 정확한 예측 결과를 벗어나면서도 넓은 부분에 분포돼 있다.</li>\n</ul>\n<p><code class=\"language-text\">일반적으로 편향과 분산은 한 쪽이 높으면 한 쪽이 낮아지는 경향</code>이 있다.</p>\n<h4 id=\"즉-편향이-높으면-분산은-낮아지고--과소적합-반대로-분산이-높으면-편향이-낮아진다--과적합\" style=\"position:relative;\"><a href=\"#%EC%A6%89-%ED%8E%B8%ED%96%A5%EC%9D%B4-%EB%86%92%EC%9C%BC%EB%A9%B4-%EB%B6%84%EC%82%B0%EC%9D%80-%EB%82%AE%EC%95%84%EC%A7%80%EA%B3%A0--%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-%EB%B0%98%EB%8C%80%EB%A1%9C-%EB%B6%84%EC%82%B0%EC%9D%B4-%EB%86%92%EC%9C%BC%EB%A9%B4-%ED%8E%B8%ED%96%A5%EC%9D%B4-%EB%82%AE%EC%95%84%EC%A7%84%EB%8B%A4--%EA%B3%BC%EC%A0%81%ED%95%A9\" aria-label=\"즉 편향이 높으면 분산은 낮아지고  과소적합 반대로 분산이 높으면 편향이 낮아진다  과적합 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>즉, 편향이 높으면 분산은 낮아지고 => 과소적합, 반대로 분산이 높으면 편향이 낮아진다 => 과적합</h4>\n<h3 id=\"덧붙여서\" style=\"position:relative;\"><a href=\"#%EB%8D%A7%EB%B6%99%EC%97%AC%EC%84%9C\" aria-label=\"덧붙여서 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>(덧붙여서)</h3>\n<p>저편향/저분산은 이상에 가깝다. 결국 데이터 분석의 목적이 무엇인지에 따라 적절한 선택을 해야 한다.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">^.^</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">결국 데이터 분석가는 <code class=\"language-text\">고편향/저분산</code> 과 <code class=\"language-text\">저편향/고분산</code> 중에서 하나를 골라야만 하며 훌륭한 데이터 분석가라면 추론할 때는 <code class=\"language-text\">고편향/저분산</code>을 고를 것이다. 어차피 데이터 분석가는 비즈니스 현장에서 상사나 이해관계자가 실제로 사용할 수 있고, 설명할 수 있는 모형을 만들어야 하니까. 아무도 이해 못하고 해석도 못해서 사용할 수 없는 모형을 만들면 안된다. 반면에 데이터 분석의 목적이 예측이라면 데이터 분석가는 <code class=\"language-text\">저편향/고분산</code>을 고를 거다. 모형이 복잡하더라도 정답에 가까운 결과물을 도출해야 하기 때문이다.</td>\n</tr>\n</tbody>\n</table>\n<p>⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀<span style=\"font-size:75%\">출처 : 감으로만 일하던 김팀장은 어떻게 데이터 좀 아는 팀장이 되었나</span></p>\n<br/>\r\n<br/>\r\n<br/>","frontmatter":{"date":"April 07, 2022","title":"다항회귀","categories":"빅분기","author":"강화정","emoji":"⁉"},"fields":{"slug":"/prods 3/"}},"prev":{"id":"985605f4-cf31-5284-a101-993083c3ce7c","html":"<p>오! 데이콘에서 실시한 대회에서 2분동안 3등을 했었다. (600명 조금 넘는 참가자 중에서!)<br/>\r\n영광의 캡쳐 … ✨<br/>\r\n(사진 넣기)</p>\n<p>최종 결과는 public 10등/private 22등을 했다 :)<br/>\r\n정말 신기하고 재미있는 경험이였다 ㅎㅎㅎㅎㅎㅎ<br/>\r\n이번 <code class=\"language-text\">전복 나이 예측 경진대회</code>를 진행하면서 많이 배우고 가는 것 같다. <br/></p>\n<p>이번 경진대회를 통해 새로 알게 된건 <code class=\"language-text\">Auto ML</code> 이다.\r\n이게 <strong>pycaret 라이브러리</strong>를 통해 머신러닝을 이용하는 것인데, 하이퍼파라미터만 내가 수정하면 되는거라\r\n손이 별로 안가고 무척 편리했다! <br/> 내가 어떤 모델을 이용해서 진행할 것인지 처음 선택할 때 도움이 많이 되었다.<br/>\r\n(마지막에는 pycaret을 이용하진 않았지만 ^^…)</p>\n<h2 id=\"아무튼-코드-설명-시작-\" style=\"position:relative;\"><a href=\"#%EC%95%84%EB%AC%B4%ED%8A%BC-%EC%BD%94%EB%93%9C-%EC%84%A4%EB%AA%85-%EC%8B%9C%EC%9E%91-\" aria-label=\"아무튼 코드 설명 시작  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>아무튼 코드 설명 시작 ~~!</h2>\n<h3 id=\"데이터-탐색\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0-%ED%83%90%EC%83%89\" aria-label=\"데이터 탐색 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터 탐색</h3>\n<p>train data set은 id, Gender, Lenght, Diameter, Height, Whole Weight, Shucked Weight, Viscra Weight, Shell Weight, Target의 칼럼을 갖고 있고\r\ntest data set은 Target을 제외한 나머지 칼럼들을 갖고 있다. shape은 (1253, 10) 그리고 (2924, 9) 로 test data가 더 많은 row를 갖고 있는 양상을 보여줬다.</p>\n<br/>","frontmatter":{"date":"April 09, 2022","title":"전복 나이 예측 경진대회","categories":"🤍데이콘🤍","author":"강화정","emoji":"🎢"},"fields":{"slug":"/dacon contest/"}},"site":{"siteMetadata":{"siteUrl":"https://7rohj.github.io","comments":{"utterances":{"repo":"https://7rohj.github.io"}}}}},"pageContext":{"slug":"/prods 4/","nextSlug":"/prods 3/","prevSlug":"/dacon contest/"}},
    "staticQueryHashes": ["1073350324","1956554647","2938748437"]}